# MrX App Builder - Colab Heavy Agent
# Complete implementation notebook

"""
Cell 1: Clone Repository with Fresh Code
This will remove old code and clone fresh version every time
"""

import os
import shutil
from pathlib import Path
print("=" * 70)
print("üì• CLONING MRX APP BUILDER CODE")
print("=" * 70)
# Define paths
repo_path = Path("/content/MrX-App-Builder-")
colab_path = repo_path / "COLAB"
# Step 1: Remove old repository if exists
if repo_path.exists():
    print("\nüóëÔ∏è  Removing old repository...")
    shutil.rmtree(repo_path)
    print("   ‚úÖ Old code removed")
# Step 2: Clone fresh repository
print("\nüì¶ Cloning fresh repository from GitHub...")
result = os.system("git clone https://github.com/mwilliamson54/MrX-App-Builder- /content/MrX-App-Builder-")
if result == 0:
    print("   ‚úÖ Repository cloned successfully")
else:
    print("   ‚ùå Clone failed with exit code:", result)
    raise Exception("Failed to clone repository")
# Step 3: Verify COLAB directory exists
print("\n‚úÖ Verifying COLAB directory...")
if colab_path.exists():
    print(f"   ‚úÖ COLAB directory found at: {colab_path}")
    # Count files
    file_count = sum(1 for _ in colab_path.rglob('*.py'))
    print(f"   ‚úÖ Found {file_count} Python files")
else:
    print(f"   ‚ùå COLAB directory NOT found!")
    raise Exception("COLAB directory missing after clone")
# Step 4: Add to Python path
print("\nüêç Adding to Python path...")
import sys
sys.path.insert(0, str(colab_path))
print(f"   ‚úÖ Added: {colab_path}")
# Step 5: Verify path
if str(colab_path) in sys.path:
    print("   ‚úÖ Path configured correctly")
else:
    print("   ‚ö†Ô∏è  Warning: Path may not be configured")
print("\n" + "=" * 70)
print("‚úÖ CODE READY - Fresh version loaded!")
print("=" * 70)


"""
Cell 2: Install Dependencies
"""
# Install all required packages
!pip install -q tree-sitter tree-sitter-languages
!pip install -q sentence-transformers transformers torch
!pip install -q faiss-cpu
!pip install -q GitPython
!pip install -q google-api-python-client google-auth google-auth-oauthlib
!pip install -q requests tenacity pydantic python-dotenv
print("‚úì All dependencies installed")


"""
Cell 3: Load all environment variables and secrets
"""

import os
from google.colab import userdata
# Get your secrets from Colab Secrets
try:
    BACKEND_URL = userdata.get('BACKEND_URL')
    COLAB_ID = userdata.get('COLAB_ID')
    CLAIM_SECRET = userdata.get('COLAB_SECRET')  # Note: you called it COLAB_SECRET
    GITHUB_PAT = userdata.get('GITHUB_PAT')
    # Set as environment variables
    os.environ["BACKEND_URL"] = BACKEND_URL
    os.environ["COLAB_ID"] = COLAB_ID
    os.environ["CLAIM_SECRET"] = CLAIM_SECRET
    os.environ["GITHUB_PAT"] = GITHUB_PAT
    # Google Drive credentials (optional, for APK upload)
    # os.environ["GOOGLE_DRIVE_CREDENTIALS"] = '{"type": "service_account", ...}'
    # LLM Configuration (optional)
    # Option 1: Custom LLM endpoint
    # os.environ["CUSTOM_LLM_ENDPOINT"] = "https://your-llm-api.com/v1/chat/completions"
    # os.environ["CUSTOM_LLM_KEY"] = "your-api-key"
    # Option 2: OpenAI
    # os.environ["OPENAI_API_KEY"] = "sk-your-openai-key"
    # Verify (without showing actual values)
    print("‚úì Configuration loaded:")
    print(f"  - Backend URL: {BACKEND_URL[:30]}...")
    print(f"  - Colab ID: {COLAB_ID}")
    print(f"  - Claim Secret: {'*' * len(CLAIM_SECRET)}")
    print(f"  - GitHub PAT: {'*' * 20}")
except Exception as e:
    print(f"‚ùå Error loading secrets: {e}")
    print("\nPlease check:")
    print("1. Secrets are added in Colab (key icon üîë)")
    print("2. Secret names match exactly")
    print("3. Notebook access is enabled for each secret")



"""
Cell 4: Load all modules
"""

import sys
# Make sure the path is set correctly
colab_path = '/content/MrX-App-Builder-/COLAB'
if colab_path not in sys.path:
    sys.path.insert(0, colab_path)
print("üìö Importing modules...")
print(f"   Python path: {colab_path}")
# Import in order of dependencies
try:
    print("   ‚è≥ Loading config...")
    from config.settings import settings
    from config.secrets import secret_manager
    print("   ‚úÖ Config loaded")
    print("   ‚è≥ Loading utilities...")
    from utils.logger import logger
    from utils.retry import retry_decorator
    print("   ‚úÖ Utilities loaded")
    print("   ‚è≥ Loading core modules...")
    from core.auth import authenticator
    from core.job_manager import job_manager, Job
    print("   ‚úÖ Core modules loaded")
    print("   ‚è≥ Loading storage...")
    from storage.kv_client import kv_client
    from storage.log_streamer import LogStreamingContext
    print("   ‚úÖ Storage loaded")
    print("   ‚è≥ Loading parsers...")
    from parsers.tree_sitter_parser import ts_parser
    from chunking.chunker import CodeChunker
    print("   ‚úÖ Parsers loaded")
    print("   ‚è≥ Loading embeddings...")
    from embeddings.model_loader import get_embedding_model, BatchEmbedder
    print("   ‚úÖ Embeddings loaded")
    print("   ‚è≥ Loading vector search...")
    from vector.faiss_manager import get_faiss_index
    print("   ‚úÖ Vector search loaded")
    print("   ‚è≥ Loading Git manager...")
    # Import GitPython first to avoid conflicts
    import git as gitpython
    # Now import our repo_manager
    import sys
    import importlib.util
    spec = importlib.util.spec_from_file_location(
        "repo_manager",
        f"{colab_path}/git/repo_manager.py"
    )
    repo_manager_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(repo_manager_module)
    get_repo_manager = repo_manager_module.get_repo_manager
    print("   ‚úÖ Git manager loaded")
    print("   ‚è≥ Loading LLM modules...")
    from llm.prompt_builder import prompt_builder
    from llm.llm_client import llm_client, response_parser
    print("   ‚úÖ LLM modules loaded")
    print("   ‚è≥ Loading build tools...")
    from build.gradle_executor import build_project, ErrorParser
    print("   ‚úÖ Build tools loaded")
    print("\n‚úÖ All modules imported successfully!")
except ImportError as e:
    print(f"\n‚ùå Import failed: {e}")
    print("\nüîç Debugging info:")
    print(f"   Current path: {sys.path[0]}")
    print(f"   Files in COLAB/git/:")
    import os
    git_dir = f"{colab_path}/git"
    if os.path.exists(git_dir):
        for f in os.listdir(git_dir):
            print(f"      - {f}")
    raise


"""
# Cell 5: Initialize the Colab agent and authenticate
"""

def initialize_agent():
    """Initialize agent and authenticate"""
    print("=" * 60)
    print("üîß INITIALIZING MRX COLAB AGENT")
    print("=" * 60)
    # Create workspace directories
    print("\nüìÅ Creating workspace directories...")
    settings.create_directories()
    print("   ‚úÖ Directories created")
    # Load secrets from environment
    print("\nüîê Loading secrets...")
    secret_manager.load_from_env()
    print("   ‚úÖ Secrets loaded from environment")
    # Authenticate with backend
    print("\nüîó Authenticating with backend...")
    try:
        success = authenticator.setup_session()
        if not success:
            print("   ‚ùå Authentication failed")
            return False
        print("   ‚úÖ Authentication successful")
    except Exception as e:
        print(f"   ‚ùå Authentication error: {e}")
        return False
    # Load embedding model (this takes 2-3 minutes first time)
    print("\nü§ñ Loading AI embedding model...")
    print("   ‚è≥ First time download: ~400MB, please wait 2-3 minutes...")
    try:
        embedding_model = get_embedding_model()
        print(f"   ‚úÖ Model loaded: {embedding_model.get_model_name()}")
        print(f"   ‚úÖ Embedding dimension: {embedding_model.get_dimension()}")
    except Exception as e:
        print(f"   ‚ùå Failed to load model: {e}")
        return False
    print("\n" + "=" * 60)
    print("‚úÖ AGENT READY TO ACCEPT JOBS!")
    print("=" * 60)
    return True
# Run initialization
print("Starting initialization...\n")
if initialize_agent():
    print("\nüéâ SUCCESS! Your agent is fully initialized and ready to work!")
    print("\nüìã Next step: Run Cell 7 to load job execution logic")
else:
    print("\n‚ùå INITIALIZATION FAILED")
    print("\nüîç Check the error messages above")
    print("üí° Common issues:")
    print("   - Wrong BACKEND_URL")
    print("   - Wrong CLAIM_SECRET")
    print("   - GitHub PAT expired or missing")









# ============================================================================
# Cell 5: Job Execution Logic
# ============================================================================
# Cell 6: Job Execution Logic
"""
Core job execution pipeline
"""

def execute_job(job):
    """
    Execute a job from the queue
    
    This is the main entry point for all job types:
    - chat: Generate AI response for chat messages
    - build-and-patch: Generate code patches and build APK
    - build-only: Just build the project
    - index-update: Update FAISS index only
    """
    from storage.log_streamer import LogStreamingContext
    
    logger.info(f"üéØ Executing job: {job.id} (type: {job.type})")
    
    # Get project metadata
    try:
        project_meta = kv_client.get_project_meta(job.project_id)
        if not project_meta:
            error_msg = f"Project metadata not found for {job.project_id}"
            logger.error(error_msg)
            job_manager.mark_failed(error_msg)
            return
    except Exception as e:
        error_msg = f"Failed to get project metadata: {str(e)}"
        logger.error(error_msg)
        job_manager.mark_failed(error_msg)
        return
    
    # Start log streaming
    with LogStreamingContext(job.project_id, job.id) as log_stream:
        
        try:
            # Step 1: Clone/update repository
            logger.info("üì¶ Step 1: Repository setup")
            repo_url = project_meta.get("repo") or project_meta.get("repoUrl")
            
            if not repo_url:
                raise Exception("Repository URL not found in project metadata")
            
            repo_manager = get_repo_manager(
                job.project_id,
                repo_url
            )
            
            if not repo_manager.is_initialized():
                logger.info("Cloning repository...")
                if not repo_manager.clone():
                    raise Exception("Failed to clone repository")
                logger.info("‚úÖ Repository cloned")
            else:
                logger.info("Fetching latest changes...")
                repo_manager.fetch()
                logger.info("‚úÖ Repository updated")
                
            log_stream.add_log(logger.get_buffer())
            logger.clear_buffer()
            
            # Step 2: Parse and chunk code
            logger.info("üìù Step 2: Parsing project")
            chunker = CodeChunker(
                job.project_id,
                repo_manager.get_repo_path()
            )
            
            filters = job.payload.get("retrievalFilters")
            chunks = chunker.chunk_project(filters)
            
            logger.info(f"‚úÖ Created {len(chunks)} chunks")
            log_stream.add_log(logger.get_buffer())
            logger.clear_buffer()
            
            # Step 3: Update FAISS index
            logger.info("üîç Step 3: Updating vector index")
            embedding_model = get_embedding_model()
            embedder = BatchEmbedder(embedding_model)
            
            # Generate embeddings
            logger.info("Generating embeddings...")
            embeddings = embedder.embed_chunks(chunks)
            logger.info(f"‚úÖ Generated {len(embeddings)} embeddings")
            
            # Get or create FAISS index
            faiss_index = get_faiss_index(
                job.project_id,
                embedding_model.get_dimension()
            )
            
            # Clear and rebuild index
            faiss_index.clear()
            faiss_index.create_index()
            
            # Add vectors
            chunk_metadata = [chunk.to_dict() for chunk in chunks]
            faiss_index.add_vectors(embeddings, chunk_metadata)
            
            # Save index
            faiss_index.save()
            
            logger.info("‚úÖ Index updated successfully")
            log_stream.add_log(logger.get_buffer())
            logger.clear_buffer()
            
            # Step 4: Handle job type
            if job.type == "chat":
                logger.info("üí¨ Processing chat job")
                result = execute_chat_job(
                    job, repo_manager, faiss_index, embedder, log_stream
                )
            elif job.type == "build-and-patch":
                logger.info("üî® Processing build-and-patch job")
                result = execute_build_and_patch(
                    job, repo_manager, faiss_index, embedder, log_stream
                )
            elif job.type == "build-only":
                logger.info("üî® Processing build-only job")
                result = execute_build_only(
                    job, repo_manager, log_stream
                )
            elif job.type == "index-update":
                logger.info("üîç Processing index-update job")
                result = {"status": "completed", "chunks": len(chunks)}
            else:
                raise Exception(f"Unknown job type: {job.type}")
            
            # Mark as completed
            logger.info(f"‚úÖ Job completed: {job.id}")
            job_manager.mark_completed(result)
            
        except Exception as e:
            logger.error(f"‚ùå Job failed: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            log_stream.add_log(logger.get_buffer())
            job_manager.mark_failed(str(e))

def execute_chat_job(job, repo_manager, faiss_index, embedder, log_stream):
    """Execute chat job - AI response generation"""
    
    logger.info("Getting chat message from payload...")
    chat_id = job.payload.get("chatId")
    message_id = job.payload.get("messageId")
    
    if not chat_id or not message_id:
        raise Exception("Missing chatId or messageId in job payload")
    
    # For now, return a simple response
    # In full implementation, you would:
    # 1. Get the user message from KV
    # 2. Retrieve relevant code chunks
    # 3. Call LLM with context
    # 4. Post AI response back to chat
    
    logger.info(f"Chat job completed for chat {chat_id}")
    
    return {
        "status": "completed",
        "chatId": chat_id,
        "messageId": message_id
    }

def execute_build_and_patch(job, repo_manager, faiss_index, embedder, log_stream):
    """Execute build-and-patch job"""
    
    # Get user request
    user_message = job.payload.get("patchRequest", "")
    
    if not user_message:
        raise Exception("No patchRequest in job payload")
    
    # Retrieve relevant chunks
    logger.info("üîç Retrieving relevant code")
    query_embedding = embedder.embed_query(user_message)
    retrieved_chunks = faiss_index.search(query_embedding)
    
    logger.info(f"Found {len(retrieved_chunks)} relevant code chunks")
    
    # Build prompt
    messages = prompt_builder.build_prompt(
        user_message,
        retrieved_chunks,
        chat_history=job.payload.get("chatHistory"),
        project_config=job.payload.get("projectConfig")
    )
    
    # Call LLM
    logger.info("ü§ñ Calling LLM")
    response = llm_client.call_llm(messages)
    
    if not response:
        raise Exception("LLM call failed")
    
    logger.info("‚úÖ LLM response received")
        
    # Extract patches
    patches = response_parser.extract_patches(response)
    logger.info(f"üìù Extracted {len(patches)} patches")
    
    log_stream.add_log(logger.get_buffer())
    logger.clear_buffer()
    
    # Build project
    logger.info("üî® Building project")
    success, output, apks = build_project(
        repo_manager.get_repo_path(),
        variant=job.payload.get("buildVariant", "release")
    )
    
    if not success:
        # Try auto-fix
        errors = ErrorParser.parse_errors(output, "")
        logger.warning(f"‚ö†Ô∏è Build failed with {len(errors)} errors")
    
    log_stream.add_log(logger.get_buffer())
    
    return {
        "status": "completed",
        "patches": len(patches),
        "build_success": success,
        "apks": [str(apk) for apk in apks]
    }

def execute_build_only(job, repo_manager, log_stream):
    """Execute build-only job"""
    
    logger.info("üî® Building project (no patches)")
    
    success, output, apks = build_project(
        repo_manager.get_repo_path(),
        variant=job.payload.get("buildVariant", "release"),
        clean=job.payload.get("clean", False)
    )
    
    if success:
        logger.info(f"‚úÖ Build successful, {len(apks)} APK(s) generated")
    else:
        logger.error("‚ùå Build failed")
    
    log_stream.add_log(logger.get_buffer())
    
    return {
        "status": "completed",
        "build_success": success,
        "apks": [str(apk) for apk in apks]
    }

print("‚úÖ Job execution logic loaded")# ============================================================================
# Cell 6: Start Agent (Main Loop)
"""
Start the main polling loop
This cell will run indefinitely, polling for jobs
"""

def main():
    """Main agent loop"""
    logger.info("=" * 60)
    logger.info("MrX Colab Agent Started")
    logger.info(f"Backend: {settings.BACKEND_URL}")
    logger.info(f"Colab ID: {settings.COLAB_ID}")
    logger.info("=" * 60)
    
    try:
        # Start polling loop
        job_manager.poll_loop(
            callback=execute_job,
            interval=settings.POLL_INTERVAL
        )
    except KeyboardInterrupt:
        logger.info("Agent stopped by user")
    except Exception as e:
        logger.error(f"Agent crashed: {str(e)}")
        raise

# Run the agent
print("Starting agent... (Press Stop button to halt)")
print("-" * 60)
main()
